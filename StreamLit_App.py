# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GUbfpNzsntiNAlGRsj5iX0ueTxRbr0j0
"""

!pip install -q streamlit xgboost

# app.py
# Streamlit Classification Model Trainer/Evaluator

import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import streamlit as st

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, label_binarize
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

from sklearn.metrics import (
    accuracy_score,
    roc_auc_score,
    precision_score,
    recall_score,
    f1_score,
    matthews_corrcoef,
    confusion_matrix,
    classification_report,
)

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier

import matplotlib.pyplot as plt

# Optional dependency
try:
    from xgboost import XGBClassifier  # type: ignore
    XGBOOST_AVAILABLE = True
except Exception:
    XGBOOST_AVAILABLE = False

MODEL_NAMES = [
    "Decision_Tree",
    "KNN",
    "Logistic_Regression",
    "naive_bayes_gaussian",
    "random_forest_classifier",
    "xgboost_classifier",
]

DROP_CANDIDATES = ["#", "Name", "ID", "Id", "index"]

def build_model(model_name: str, scale_numeric: bool, n_classes: int):
    if model_name == "Decision_Tree":
        return DecisionTreeClassifier(random_state=42), True
    if model_name == "KNN":
        return KNeighborsClassifier(n_neighbors=5), True
    if model_name == "Logistic_Regression":
        return LogisticRegression(max_iter=2000), True
    if model_name == "naive_bayes_gaussian":
        return GaussianNB(), True
    if model_name == "random_forest_classifier":
        return RandomForestClassifier(n_estimators=300, random_state=42), True
    if model_name == "xgboost_classifier":
        if not XGBOOST_AVAILABLE:
            st.error("xgboost is not installed.")
            st.stop()
        if n_classes > 2:
            clf = XGBClassifier(n_estimators=500, objective="multi:softprob", num_class=n_classes, random_state=42)
        else:
            clf = XGBClassifier(n_estimators=500, objective="binary:logistic", random_state=42)
        return clf, True
    raise ValueError(f"Unknown model: {model_name}")

def make_preprocessor(X: pd.DataFrame, scale_numeric: bool):
    numeric_cols = X.select_dtypes(include=["number", "bool"]).columns.tolist()
    categorical_cols = [c for c in X.columns if c not in numeric_cols]
    num_steps = [("imputer", SimpleImputer(strategy="median"))]
    if scale_numeric:
        num_steps.append(("scaler", StandardScaler()))
    cat_transformer = Pipeline(steps=[("imputer", SimpleImputer(strategy="most_frequent")), ("onehot", OneHotEncoderSafe())])
    return ColumnTransformer(transformers=[("num", Pipeline(steps=num_steps), numeric_cols), ("cat", cat_transformer, categorical_cols)], remainder="drop")

class OneHotEncoderSafe:
    def __init__(self):
        from sklearn.preprocessing import OneHotEncoder
        try: self.enc = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
        except TypeError: self.enc = OneHotEncoder(handle_unknown="ignore", sparse=False)
    def fit(self, X, y=None): self.enc.fit(X); return self
    def transform(self, X): return self.enc.transform(X)
    def fit_transform(self, X, y=None): return self.enc.fit_transform(X)

def compute_metrics(y_true, y_pred, y_proba, labels):
    n_classes = len(labels)
    is_binary = n_classes == 2
    avg = "binary" if is_binary else "macro"
    metrics = {
        "Accuracy": accuracy_score(y_true, y_pred),
        "Precision": precision_score(y_true, y_pred, average=avg, zero_division=0),
        "Recall": recall_score(y_true, y_pred, average=avg, zero_division=0),
        "F1 Score": f1_score(y_true, y_pred, average=avg, zero_division=0),
        "MCC Score": matthews_corrcoef(y_true, y_pred),
    }
    try:
        if y_proba is not null:
            if is_binary: metrics["AUC Score"] = roc_auc_score(y_true, y_proba[:, 1])
            else: metrics["AUC Score"] = roc_auc_score(label_binarize(y_true, classes=labels), y_proba, multi_class="ovr", average="macro")
    except: metrics["AUC Score"] = np.nan
    return metrics

def plot_confusion_matrix(cm, labels):
    fig, ax = plt.subplots(); ax.imshow(cm)
    ax.set_xticks(np.arange(len(labels))); ax.set_yticks(np.arange(len(labels)))
    ax.set_xticklabels(labels, rotation=45); ax.set_yticklabels(labels)
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]): ax.text(j, i, str(cm[i, j]), ha="center", va="center")
    return fig

st.set_page_config(page_title="ML Classifier Evaluator", layout="wide")
st.title("▁ Classification Models Evaluator (Streamlit)")
uploaded = st.file_uploader("Upload Dataset (CSV)", type=["csv"])

with st.sidebar:
    st.header("⚙℘ Settings")
    model_name = st.selectbox("Select Model", MODEL_NAMES)
    test_size = st.slider("Test Size", 0.1, 0.4, 0.2)
    random_state = st.number_input("Random State", value=42)
    stratify_opt = st.checkbox("Stratify split", value=True)

if uploaded is not None:
    df = pd.read_csv(uploaded)
    if df.shape[0] < 10:
        st.error("Dataset too small.")
    else:
        st.subheader("Preview")
        st.dataframe(df.head(20), use_container_width=True)
        target_col = st.selectbox("Select Target Column", df.columns.tolist())
        X = df.drop(columns=[target_col])
        y = df[target_col]
        y_series = y.astype("category").cat.codes if y.dtype == "object" else y.astype(int)
        mask = ~pd.isna(y_series)
        X, y_series = X.loc[mask], y_series.loc[mask]
        labels = np.unique(y_series)
        X_train, X_test, y_train, y_test = train_test_split(X, y_series, test_size=test_size, random_state=int(random_state), stratify=y_series if stratify_opt else None)
        pipeline = Pipeline(steps=[("preprocess", make_preprocessor(X, model_name in ["KNN", "Logistic_Regression"])), ("model", build_model(model_name, False, len(labels))[0])])
        if st.button("  Train & Evaluate", type="primary"):
            pipeline.fit(X_train, y_train)
            y_pred = pipeline.predict(X_test)
            metrics = compute_metrics(y_test, y_pred, pipeline.predict_proba(X_test) if hasattr(pipeline, "predict_proba") else None, labels)
            st.subheader("✅ Metrics")
            st.write(metrics)
            st.pyplot(plot_confusion_matrix(confusion_matrix(y_test, y_pred), labels))
else:
    st.info("Please upload a CSV to begin.")